{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66386297-8e87-43e6-8ce5-00b9af4f5770",
   "metadata": {},
   "source": [
    "# DNN-Based DDoS Anomaly Detection in the Network Data Plane"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea79fb1-1d2e-4d83-b248-65392ecf5350",
   "metadata": {},
   "source": [
    "In this 4-part notebook series, we show how a quantized neural network (QNN) can be trained to classify packets as belonging to DDoS (malicious) or regular (benign) network traffic flows. The model is trained with quantized weights and activations, and we use the [Brevitas](https://github.com/Xilinx/brevitas) framework to train the QNN. The model is then converted into an FPGA-friendly RTL implementation for high-throughput inference, which can be integrated with a packet-processing pipeline in the network data plane.\n",
    "\n",
    "This notebook series is composed of 4 parts. Below is a brief summary of what each part covers.\n",
    "\n",
    "[Part 1](./1-train.ipynb): How to use Brevitas to train a quantized neural network for our target application, which is classifying packets as belonging to malicious/DDoS or benign/normal network traffic flows. The output trained model at the end of this part is a pure software implementation, i.e. it cannot be converted to a custom RTL FINN model to run on an FPGA just yet.\n",
    "\n",
    "[Part 2](./2-prepare.ipynb): This notebook focuses on taking the output software model from the previous part and preparing it for hardware-friendly implementation using the FINN framework. The notebook describes the steps taken to \"surgery\" the software model in order for hardware generation via FINN. We also verify that all the changes made to the software model in this notebook DO NOT affect the output predictions in the \"surgeried\" model.\n",
    "\n",
    "[Part 3](./3-build.ipynb): In this notebook, we use the FINN framework to build the custom RTL accelerator for our target model. FINN can generate a variety of RTL accelerators, and this notebook covers some build configuration parameters that influence these outputs.\n",
    "\n",
    "[Part 4](./4-verify.ipynb): The generated hardware is simulated using cycle-accurate RTL simulation tools, and its outputs are compared against the original software-only model trained in part one. The output model from this step is now ready to be integrated into a larger FPGA design, which in this context is a packet-processing network data plane pipeline designed for identifying anomalous DDoS flows from benign flows.\n",
    "\n",
    "This tutorial series is a supplement to our demo paper presented at EuroP4 2023 workshop, titled [Enabling DNN Inference in the Network Data Plane](https://dl.acm.org/doi/10.1145/3630047.3630191). You can cite our work using the following BibTeX snippet:\n",
    "\n",
    "```\n",
    "@inproceedings{siddhartha2023enabling,\n",
    "  title={Enabling DNN Inference in the Network Data Plane},\n",
    "  author={Siddhartha and Tan, Justin and Bansal, Rajesh and Chee Cheun, Huang and Tokusashi, Yuta and Yew Kwan, Chong and Javaid, Haris and Baldi, Mario},\n",
    "  booktitle={Proceedings of the 6th on European P4 Workshop},\n",
    "  pages={65--68},\n",
    "  year={2023}\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373ae9cd-b23c-4c39-87b9-1b44ee73dc9e",
   "metadata": {},
   "source": [
    "# Motivation: Data Plane AI\n",
    "\n",
    "Programmable network devices, such as SmartNICs (e.g. AMD Alveo SmartNICs), DPUs (e.g. AMD Pensando DPU), and programmable switches (e.g. Intel Tofino), are gaining popularity as they enable faster pace of innovation and more customisability for the end-user. Vendors have also adopted this trend, supporting languages such as P4 (e.g. Pensando and Tofino are P4-programmable) and eBPF (e.g. eBPF offload to Netronome FPCs), which has inspired network engineers to test and implement many new interesting use-cases in the network data plane, such as traffic classification, in-network consensus, in-network DNS, and more.\n",
    "\n",
    "Modern machine learning methods, such as deep neural networks (DNNs), have had a profound impact on many application domains, most notably on computer vision and natural language processing. As expected, there is a long-tail of applications that can benefit from modern DNNs, and networking applications are not an exception. There is an increased interest in bringing more intelligence to networking applications, and hence a strong demand to enable DNN inference in the network data plane, often referred to as **Data Plane AI**.\n",
    "\n",
    "However, in order to enable Data Plane AI, the DNN inference accelerator needs to be able to handle the challenging high data-rate environment of the network data plane. Furthermore, programmable network devices either have limited or unsuitable compute resources for DNNs in the data plane (extraction of features and/or execution of DNN model). Hence, end-users often fall back to executing DNN-based inference in the control plane, which is not suitable for low-latency per-packet operations at high line-rates. The figure below shows the high-level architectural motivations behind this work.\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "    <img src=\"motivation_arch.png\" alt=\"Motivation architecture\" width=\"75%\"/>\n",
    "</div>\n",
    "\n",
    "Here, we only show the RX datapath of a hypothetical networking device that has an FPGA fabric for mapping FINN inference engine designs to. The programmable packet processor can compute features and issue inference requests to the FINN accelerator, which computes the output using weights that were trained offline, and feeds the prediction back into the packet processor. The packet processor can then take this prediction result and use it to make packet/flow forwarding decisions in the data plane. In order to enable this vision, ideally, the inference engine should be capable of inference throughputs that meet peak observed packet-rates in the data plane, which on modern data-center devices, can be in the order of tens-to-hundreds of millions of packets-per-second.\n",
    "\n",
    "This notebook series focuses on the FINN inference engine design for a Network Intrusion Detection System (NIDS) use-case. One of the goals of NIDS is to classify active traffic flows into malicious (e.g. DDoS attacks) or benign categories. Flows that are classified as malicious can be dropped and/or blocked, and future prevention mechanisms can then be integrated into the NIDS. Our case study focuses on the first step of NIDS, which is modeled as an anomaly detection task. In this notebook series, we showcase how to train DNN models on open-source network traffic datasets, and how to optimize and build them for high-throughput deployments in FPGA-based SmartNICs (e.g., Alveo U250 with OpenNIC shell)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64ebd5c-8bc6-4b50-be59-946a96a19cf2",
   "metadata": {},
   "source": [
    "# Part 1: Training a QNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db75b0c-cf48-413a-b70d-88402c7875d1",
   "metadata": {},
   "source": [
    "### House-keeping\n",
    "\n",
    "Let's first get started with some house-keeping by importing all relevant libraries and packages relevant to this noteobok. We will also declare some constants that are global to this notebook (e.g. paths to folders, etc). This will help to keep things clear and organised. Note that variables storing constants are standardized to be all uppercase (e.g. `EXAMPLE_DIR` instead of `example_dir`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2015ccb6-8d11-4a29-9dc7-433919d537db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "from brevitas.nn import QuantLinear, QuantReLU\n",
    "from tqdm import tqdm, trange\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.dataset import CICIDS2017_PerPacket\n",
    "from utils.train_test import train, test\n",
    "\n",
    "# Setting seeds for reproducibility\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "# Path to this end-to-end example's directory\n",
    "EXAMPLE_DIR = join(os.environ['FINN_ROOT'], \"notebooks/end2end_example/ddos-anomaly-detector\")\n",
    "\n",
    "# Path to where datasets are stored\n",
    "DATASET_DIR = join(EXAMPLE_DIR, \"data\")\n",
    "\n",
    "# Path to build directory to write outputs from this notebook to\n",
    "BUILD_DIR = join(EXAMPLE_DIR, \"build\", \"part_01\")\n",
    "os.makedirs(BUILD_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4261442f-3a85-4a05-81c6-b0dc14d94f4d",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "Let's get started by first understanding the dataset. We use the [CIC-IDS2017](https://www.unb.ca/cic/datasets/ids-2017.html) dataset released publicly by the Canadian Institute for Cybersecurity. It is an intrusion detection dataset designed to enable network researchers to train machine learning models for classifying network flows. The dataset was collected by creating realistic background network traffic while various common and recent types of network security attacks (e.g., DoS, DDoS, Botnet, Heartbleed, etc.) were being carried out on target machines. More details on the setup and data collection can be found on their page.\n",
    "\n",
    "The dataset provides **per-flow** features and labels, which is insufficient for training deep neural network (DNN) models that carry out **per-packet** inference in the network data plane. In order to enable per-packet inference in the network data plane, we preprocess the raw PCAP files (also released as part of the CIC-IDS2017 dataset) and reverse-engineer the labels based on the descriptions provided by the dataset authors. For simplicity, we convert the multi-class attack classification into a binary class, where the anomaly detector is trained to classify an active flow either as `ATTACK` or `BENIGN`. During this pre-processing step, we only compute features that can be efficiently tracked on a per-packet level in the proposed hardware implementation. For example, we do not compute means and variances, and instead rely on the DNN model to infer relationships between simpler (e.g., accumulated) flow-level features. Examples of features we compute in the pre-processing step:\n",
    "\n",
    "- `FlowDuration`: Current duration of a flow (in $\\micro$s)\n",
    "- `TotalPkts`: Total packets received in a flow\n",
    "- `TotalRecvBytes`: Total received bytes in a flow\n",
    "- `MaxIAT`: Maximum Inter-Arrival Time of packets in a flow\n",
    "\n",
    "To further simplify the training task for this demo, we preprocess only a fraction of the available PCAP network trace. The final per-packet dataset was constructed by analyzing a period of 5 minutes in the PCAP capture (Wednesday, 5th July 2017, 10:43 AM–10:48 AM) when a DDoS attack (`DoS Hulk`) was occurring, resulting in a dataset of >600K samples with balanced class distribution in the labels.\n",
    "\n",
    "More details about the dataset and the modeling task can be found in [our demo paper here](https://dl.acm.org/doi/abs/10.1145/3630047.3630191).\n",
    "\n",
    "For this notebook, we have split the dataset into train and test sets, which can be found in the `data/` directory as `cicids2017-split.train.csv` and `cicids2017-split.test.csv` respectively. The train and test splits are created with stratify enabled, such that both split sets have a similar distribution of labels contained inside. We have also provided a python utility class (`CICIDS2017_PerPacket`) for loading this dataset, which can be [found here](./utils/dataset.py). This utility class carries out binarization of inputs/outputs, and also allows the programmer to select which features to use for training/testing. [Binarization of inputs](https://ev.fe.uni-lj.si/1-2-2019/Murovic.pdf) has been demonstrated to be capable of achieving good (90%+) accuracy, so we choose to adopt this strategy for faster hardware implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2131b126-d54d-49c1-b052-390dfe1bcaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's load the train and test sets\n",
    "train_set_fpath = join(DATASET_DIR, \"cicids2017-split.train.csv\")\n",
    "test_set_fpath = join(DATASET_DIR, \"cicids2017-split.test.csv\")\n",
    "dataset = CICIDS2017_PerPacket.load_from_split(train_set_fpath, test_set_fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68693ba-40e1-410f-836d-0e9bc8457981",
   "metadata": {},
   "source": [
    "Note how the metadata information about the train/test sets is printed. There are 20 per-packet features in this dataset that can be used to train the model. In this example, we use the following four features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59391b3c-4bb1-44bf-82d7-b8b68505f660",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_use = [\"total_bytes\", \"duration_usec\", \"total_pkts\", \"total_urg\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecaf3148-b7bc-4fd0-8523-4b2ee57720b7",
   "metadata": {},
   "source": [
    "We can then use our dataset instance to get binarized train and test sets based on these 4 features. Note the metadata information about the train/test sets that tell us the total input and output bitwidth. The ordering of the features also matters, as it will determine how the inputs are fed into the DNN. We have selected some default sensible values for the bitwidth for each of these input features, which you can inspect or modify in the source code (see `_init_bitwidth_dict` method). Note that this step may take up to a minute to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c4e4db-0a23-4235-b05d-a3910b32e9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set, dataset_metadata = dataset.get_binarized_train_test_sets(features_to_use)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd10896-f8c5-4b54-a79f-26db400ec529",
   "metadata": {},
   "source": [
    "Let's look at our train and test sets that were created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7331dc04-9d96-491a-a6ed-ab3c4b674bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Samples in each set: train = {len(train_set)}, test = {len(test_set)}\") \n",
    "print(f\"Shape of one input sample: {train_set[0][0].shape}\")\n",
    "print(f\"First input sample: {train_set[0][0]}\")\n",
    "print(f\"First 10 input labels: {train_set[:10][1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4275953-f390-45e6-ba3b-32c635aec245",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "Now that we have the binarized dataset, let's move on to the training!\n",
    "\n",
    "We will start by first wrapping the dataset in PyTorch's `DataLoader` class. This will allow us to create batches of input data easily for each training iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc3223f-bcf9-4149-9cc8-056463b8cdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch size to use during training\n",
    "batch_size = 1000\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c22465-73b0-4238-8465-d95bafee2d66",
   "metadata": {},
   "source": [
    "Note that we don't need to shuffle the test data. Let's inspect the shape of the tensor used during training, making sure that the `batch_size` dimension is now in effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0dc58c-95ee-49b2-a2d6-cfea3a7694a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in train_loader:\n",
    "    print(\"Input shape for 1 batch: \" + str(x.shape))\n",
    "    print(\"Label shape for 1 batch: \" + str(y.shape))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab13b71b-5e2c-434a-bc2b-56038b7c645d",
   "metadata": {},
   "source": [
    "Let's now look into declaring a model. For this demo, we use a simple Multi-Layer Perceptron (MLP) model with quantized weights and activations. Quantization allows us to tradeoff small drops in accuracy for significant gains in inference performance on FPGAs. We can train quantized MLP models using quantization-aware training (QAT) capabilities offered by Brevitas.\n",
    "\n",
    "Our MLP will have three fully-connected (FC) layers in total: two hidden layers with 32 neurons, and a final output layer with a single output, all using 2-bit weights. We'll use 2-bit quantized ReLU activation functions, and apply batch normalization between each FC layer and its activation.\n",
    "\n",
    "In case you'd like to experiment with different quantization settings or topology parameters, we'll define all these topology settings as variables. Note that for `input_size` and `num_classes`, we are using the dataset metadata that was generated during the binarization of our dataset in the steps above. These two fields correspond to total input bitwidth and total output bitwidth respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdba4d6e-010c-4674-a6d1-277008cdbe1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = dataset_metadata[\"total_in_bitwidth\"]\n",
    "hidden1 = 32\n",
    "hidden2 = 32\n",
    "weight_bit_width = 2\n",
    "act_bit_width = 2\n",
    "num_classes = dataset_metadata[\"total_out_bitwidth\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b8556d-8356-49bb-91e6-ee48c1590fbd",
   "metadata": {},
   "source": [
    "Now we can define our MLP using the layer primitives provided by Brevitas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46379e16-2967-4192-8736-de7b9fd93067",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "      QuantLinear(input_size, hidden1, bias=True, weight_bit_width=weight_bit_width),\n",
    "      nn.BatchNorm1d(hidden1),\n",
    "      nn.Dropout(0.5),\n",
    "      QuantReLU(bit_width=act_bit_width),\n",
    "      QuantLinear(hidden1, hidden2, bias=True, weight_bit_width=weight_bit_width),\n",
    "      nn.BatchNorm1d(hidden2),\n",
    "      nn.Dropout(0.5),\n",
    "      QuantReLU(bit_width=act_bit_width),\n",
    "      QuantLinear(hidden2, num_classes, bias=True, weight_bit_width=weight_bit_width)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a26d862-cf05-43d6-95b4-2e37db0c05c6",
   "metadata": {},
   "source": [
    "Note that the MLP's output is not yet quantized. Even though we want the final output of our MLP to be a binary (0/1) value indicating the classification, we've only defined a single-neuron FC layer as the output. While training the network we'll pass that output through a sigmoid function as part of the loss criterion, which [gives better numerical stability](https://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html).\n",
    "\n",
    "Later on in a different notebeook, after we're done training the network, we will add a quantization node at the end before we export it to the FINN tool for generating our neural network hardware accelerator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdd08b5-ceb5-48e2-92b9-fc53ef2f45a3",
   "metadata": {},
   "source": [
    "For training a DNN model, GPUs can significantly speed-up the process. We check for availability of a GPU and if available, define it as the target device. For this notebook, we will train the model for 20 epochs using (i) a learning rate of `0.001`, (ii) the Adam Optimizer, and (iii) `BCEWithLogitsLoss` as our loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac76eec6-bdf0-4606-b306-cbc5afd7e810",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Target device: {device}\")\n",
    "\n",
    "# training parameters\n",
    "num_epochs = 20\n",
    "lr = 0.001\n",
    "\n",
    "# loss criterion and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.999))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d02e546-21fb-4dc4-94f8-15ee72fdc8da",
   "metadata": {},
   "source": [
    "Let's start the training loop. Note, depending on your target device, model and dataset size, this step may take a long time to complete. However, typically this a one-time process to train a model, and the following notebooks in this series will use a trained model checkpoint for creating optimized hardware implementations to run on an FPGA.\n",
    "\n",
    "For simplicity, we have provided train and test utility methods in [utils/train_test.py](./utils/train_test.py). Both these methods use the DataLoader, which feeds the model with a new predefined batch of train/test data in each iteration, until the entire dataset is fed to the model. Running through all repetitions of this process until all training data has been run through the model is called an `epoch`. Both `train()` and `test()` methods have been imported in the house-keeping cell above, and are used in the training loop below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f0ac8c-22ea-4141-8ab0-2b9b9de453b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep track of loss and test accuracy after each epoch\n",
    "running_loss = []\n",
    "running_test_acc = []\n",
    "\n",
    "# save the model that performs the best on test set\n",
    "best_acc_model_path = join(BUILD_DIR, \"best_acc_model.pth\")\n",
    "cur_best_acc = 0.0\n",
    "\n",
    "t = trange(num_epochs, desc=\"Training loss\", leave=True)\n",
    "for epoch in t:\n",
    "        loss_epoch = train(model, train_loader, optimizer, criterion, device)\n",
    "        test_acc = test(model, test_loader, device)\n",
    "\n",
    "        # save model if it beats current best acc on test set\n",
    "        if test_acc > cur_best_acc:\n",
    "            torch.save(model.state_dict(), best_acc_model_path)\n",
    "            cur_best_acc = test_acc\n",
    "    \n",
    "        # update tqdm status bar\n",
    "        t.set_description(\"Loss = %f test acc. = %f, best test acc. = %f\" % (np.mean(loss_epoch), test_acc, cur_best_acc))\n",
    "        t.refresh()\n",
    "\n",
    "        # append for plotting later\n",
    "        running_loss.append(loss_epoch)\n",
    "        running_test_acc.append(test_acc)\n",
    "\n",
    "# reload model with weights from best acc model\n",
    "model = model.cpu()\n",
    "trained_state_dict = torch.load(best_acc_model_path)\n",
    "model.load_state_dict(trained_state_dict, strict=True)\n",
    "os.remove(best_acc_model_path)\n",
    "print(f\"Loaded trained model with best test accuracy of: {100*cur_best_acc:.4f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8c888a-de91-46c1-8f35-0e0db7d7fc0a",
   "metadata": {},
   "source": [
    "### Evaluating the model\n",
    "\n",
    "Let's plot the loss and accuracy across epochs. We first define a useful utility function for plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c6f0ac-b753-4259-bbc4-cad5cc26e8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_plot(yvalues: list[float], title: str, xlabel: str, ylabel: str):\n",
    "    \"\"\"\n",
    "    Creates a matplotlib plot using input data. X-axis values are treated as\n",
    "    implicit indices of input list of y-axis values.\n",
    "\n",
    "    Args:\n",
    "\n",
    "        yvalues (list[float]): List of float y-axis values.\n",
    "\n",
    "        title (str): Title of plot.\n",
    "\n",
    "        xlabel (str): X-axis label.\n",
    "\n",
    "        ylabel (str): Y-axis label.\n",
    "\n",
    "    Returns: None\n",
    "    \"\"\"\n",
    "    x_axis = [i for i in range(len(yvalues))]\n",
    "    plt.plot(x_axis, yvalues)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8958fca5-a62e-4023-8d6b-b212538b7fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "loss_per_epoch = [np.mean(loss_per_epoch) for loss_per_epoch in running_loss]\n",
    "display_plot(loss_per_epoch, \"Training Loss\", \"Epoch\", \"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58707db9-a440-447b-a18d-b1c54a9186d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "acc_per_epoch = [100*np.mean(acc_per_epoch) for acc_per_epoch in running_test_acc]\n",
    "display_plot(acc_per_epoch, \"Test Accuracy\", \"Epoch\", \"Accuracy (%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40597c7b-4653-435a-b188-5f0b8b5f8f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Final model test accuracy = {100*test(model, test_loader, device):.4f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7853637-d3ec-4263-8ba6-8c46ac78238b",
   "metadata": {},
   "source": [
    "### Improving the model\n",
    "\n",
    "There are many things that can be done for improving the model's accuracy. Strategies such as making the model larger, trying a different combination of features, changing model topology, etc can all influence the outcome, where domain expertise can also play a significant role. This exercise is left for the network machine learning engineer to experiment with.\n",
    "\n",
    "For now, we simply save the model into our build directory for part one, and end this first notebook in the series. In part 2, we will use this trained model checkpoint and perform \"surgery\" on it to prepare it for the FINN framework. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b99f0d2-5e8e-4d10-acb7-068bfaea1e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model_to = join(BUILD_DIR, \"trained_model.pth\")\n",
    "torch.save(model.state_dict(), save_model_to)\n",
    "\n",
    "# save the dataset_metadata as well for future use\n",
    "with open(join(BUILD_DIR, \"dataset_metadata.json\"), \"w\") as fp:\n",
    "    json.dump(dataset_metadata, fp, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
