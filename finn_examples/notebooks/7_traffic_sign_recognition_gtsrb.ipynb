{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize the accelerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn_examples import models\n",
    "accel = models.cnv_w1a1_gtsrb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Expected input shape and datatype: %s %s\" % (str(accel.ishape_normal), str(accel.idt)))\n",
    "print(\"Expected output shape and datatype: %s %s\" % (str(accel.oshape_normal), str(accel.odt)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the GTSRB dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "import urllib\n",
    "import numpy as np\n",
    "dataset_local = \"/tmp/traffic-signs-data.zip\"\n",
    "if not path.isfile(dataset_local):\n",
    "    dataset_url = \"https://d17h27t6h515a5.cloudfront.net/topher/2017/February/5898cd6f_traffic-signs-data/traffic-signs-data.zip\"\n",
    "    urllib.request.urlretrieve(dataset_url, dataset_local)\n",
    "    ! unzip {dataset_local} -d /tmp\n",
    "\n",
    "dataset_dict = np.load(\"/tmp/test.p\")\n",
    "testx = dataset_dict[\"features\"]\n",
    "testy = dataset_dict[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtsrb_classes = [\n",
    "    '20 Km/h', \n",
    "    '30 Km/h', \n",
    "    '50 Km/h', \n",
    "    '60 Km/h', \n",
    "    '70 Km/h', \n",
    "    '80 Km/h', \n",
    "    'End 80 Km/h', \n",
    "    '100 Km/h', \n",
    "    '120 Km/h', \n",
    "    'No overtaking', \n",
    "    'No overtaking for large trucks', \n",
    "    'Priority crossroad', \n",
    "    'Priority road', \n",
    "    'Give way', \n",
    "    'Stop', \n",
    "    'No vehicles', \n",
    "    'Prohibited for vehicles with a permitted gross weight over 3.5t including their trailers, and for tractors except passenger cars and buses', \n",
    "    'No entry for vehicular traffic', \n",
    "    'Danger Ahead', \n",
    "    'Bend to left', \n",
    "    'Bend to right', \n",
    "    'Double bend (first to left)', \n",
    "    'Uneven road', \n",
    "    'Road slippery when wet or dirty', \n",
    "    'Road narrows (right)', \n",
    "    'Road works', \n",
    "    'Traffic signals', \n",
    "    'Pedestrians in road ahead', \n",
    "    'Children crossing ahead', \n",
    "    'Bicycles prohibited', \n",
    "    'Risk of snow or ice', \n",
    "    'Wild animals', \n",
    "    'End of all speed and overtaking restrictions', \n",
    "    'Turn right ahead', \n",
    "    'Turn left ahead', \n",
    "    'Ahead only', \n",
    "    'Ahead or right only', \n",
    "    'Ahead or left only', \n",
    "    'Pass by on right', \n",
    "    'Pass by on left', \n",
    "    'Roundabout', \n",
    "    'End of no-overtaking zone', \n",
    "    'End of no-overtaking zone for vehicles with a permitted gross weight over 3.5t including their trailers, and for tractors except passenger cars and buses', \n",
    "    'Not a roadsign'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataset shape is \" + str(testx.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify a single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_single_x = testx[0]\n",
    "test_single_y = testy[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.imshow(test_single_x)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Expected class is:\\n%s\" % (gtsrb_classes[test_single_y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accel_y = accel.execute(test_single_x.reshape(accel.ishape_normal))\n",
    "print(\"Accelerator result is:\\n%s\" % (gtsrb_classes[np.argmax(accel_y)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate accuracy on GTSRB test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 421\n",
    "total = testx.shape[0]\n",
    "accel.batch_size = batch_size\n",
    "n_batches = int(total / batch_size)\n",
    "\n",
    "batch_imgs = testx.reshape(n_batches, batch_size, -1)\n",
    "batch_labels = testy.reshape(n_batches, batch_size)\n",
    "obuf_normal = np.empty_like(accel.obuf_packed_device)\n",
    "print(\"Ready to run validation, test images tensor has shape %s\" % str(batch_imgs.shape))\n",
    "print(\"Accelerator buffer shapes are %s for input, %s for output\" % (str(accel.ishape_packed), str(accel.oshape_packed)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok = 0\n",
    "nok = 0\n",
    "for i in range(n_batches):\n",
    "    ibuf_normal = batch_imgs[i].reshape(accel.ibuf_packed_device.shape)\n",
    "    exp = batch_labels[i]\n",
    "    # to avoid the slower software implementation during data unpacking,\n",
    "    # we make manual calls to buffer copies and execute_on_buffers\n",
    "    # all this could have been replaced with accel.execute() otherwise\n",
    "    accel.copy_input_data_to_device(ibuf_normal)\n",
    "    accel.execute_on_buffers()\n",
    "    obuf_normal = np.empty_like(accel.obuf_packed_device)\n",
    "    accel.copy_output_data_from_device(obuf_normal)\n",
    "    # this line provides fast unpacking using numpy primitives\n",
    "    # instead of using FINN's unpack functions\n",
    "    quick_out = obuf_normal.view(np.uint16).reshape(accel.batch_size, 44)\n",
    "    obuf_argmax = np.argmax(quick_out, axis=-1)\n",
    "    ok_batch = (obuf_argmax == exp).sum()\n",
    "    nok_batch = (batch_size-ok_batch)\n",
    "    ok += ok_batch\n",
    "    nok += nok_batch\n",
    "    \n",
    "    print(\"batch %d / %d : total OK %d NOK %d\" % (i+1, n_batches, ok, nok))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = 100.0 * ok / (total)\n",
    "print(\"Final accuracy: {}%\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run built-in benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accel.batch_size = 100\n",
    "accel.throughput_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
