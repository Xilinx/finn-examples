{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize the accelerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn_examples import models\n",
    "print(list(filter(lambda x: \"mnist\" in x, dir(models))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accel = models.tfc_w1a1_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Expected input shape and datatype: %s %s\" % (str(accel.ishape_normal()), str(accel.idt())))\n",
    "print(\"Expected output shape and datatype: %s %s\" % (str(accel.oshape_normal()), str(accel.odt())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the MNIST dataset\n",
    "\n",
    "Use the `dataset_loading` package to get easy Python access to MNIST dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_loading import mnist\n",
    "trainx, trainy, testx, testy, valx, valy = mnist.load_mnist_data(\"/tmp\", download=True, one_hot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify a single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_single_x = testx[0].reshape(28, 28)\n",
    "test_single_y = testy[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.imshow(test_single_x, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Expected class is %d\" % test_single_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accel_in = test_single_x.reshape(accel.ishape_normal())\n",
    "print(\"Input buffer shape is %s and datatype is %s\" % (str(accel_in.shape), str(accel_in.dtype)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accel_out = accel.execute(accel_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Returned class is %d\" % accel_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "accel_out = accel.execute(accel_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate accuracy on entire MNIST test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "batch_size = 1000\n",
    "total = testx.shape[0]\n",
    "accel.batch_size = batch_size\n",
    "n_batches = int(total / batch_size)\n",
    "\n",
    "batch_imgs = testx.reshape(n_batches, batch_size, -1)\n",
    "batch_labels = testy.reshape(n_batches, batch_size)\n",
    "obuf_normal = np.empty_like(accel.obuf_packed_device)\n",
    "print(\"Ready to run validation, test images tensor has shape %s\" % str(batch_imgs.shape))\n",
    "print(\"Accelerator buffer shapes are %s for input, %s for output\" % (str(accel.ishape_packed()), str(accel.oshape_packed())) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok = 0\n",
    "nok = 0\n",
    "for i in range(n_batches):\n",
    "    ibuf_normal = batch_imgs[i].reshape(accel.ishape_normal())\n",
    "    exp = batch_labels[i]\n",
    "    obuf_normal = accel.execute(ibuf_normal)\n",
    "    ret = np.bincount(obuf_normal.flatten() == exp.flatten())\n",
    "    nok += ret[0]\n",
    "    ok += ret[1]\n",
    "    print(\"batch %d / %d : total OK %d NOK %d\" % (i, n_batches, ok, nok))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = 100.0 * ok / (total)\n",
    "print(\"Final accuracy: {}%\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_validation():\n",
    "    for i in range(n_batches):\n",
    "        ibuf_normal = batch_imgs[i].reshape(accel.ishape_normal())\n",
    "        exp = batch_labels[i]\n",
    "        accel.execute(ibuf_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_validation_time = %timeit -n 5 -o run_validation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"%f images per second including data movement\" % (total / float(full_validation_time.best)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run some more built-in benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accel.throughput_test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
